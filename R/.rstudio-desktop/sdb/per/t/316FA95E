{
    "collab_server" : "",
    "contents" : "---\ntitle: \"ANLY 500-53 Laboratory #1 Report\"\nauthor: \"Liangquan Zhou\"\ndate: \"Aug 19, 2017\"\noutput: pdf_document\n---\n  \n```{r setup, include=T, echo = T, message=F, warning=F}\n# Load R packages\nknitr::opts_chunk$set(echo = TRUE)\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(nortest)\nlibrary(BSDA)\n```\n\n## Chapter 7\n\n### 1. Are there significant differences in ratings of specific product/service attributes in the 2014CustomerSurvey.csv data file?\n```{r Q1, echo = T, comment = NA}\nCustomerSurvey2014 = read.csv(file = \"CustomerSurvey2014.csv\", stringsAsFactors = FALSE)\nCustomerSurvey2014[is.na(CustomerSurvey2014)] <- \"NorthA\"\ncountByRegion <- table(CustomerSurvey2014$Region, CustomerSurvey2014$Quality)\ncountByRegion\nattach(CustomerSurvey2014)\n\n# find the proportion of “Top box”(Level 4 or 5) responses by region. \ntop_response <- apply(countByRegion, 1, function(x) sum(x[4], x[5]))\ntotal_response <- apply(countByRegion, 1, sum)\ntop_propotion <- top_response/total_response\ntop_propotion %>% round(2)\n\n```\n\n### 2.In the data file OnTimeDelivery.csv, has the proportion of on-time deliveries in 2014 significantly improved since 2010?\n```{r Q2, echo=T, comment= NA}\nResponseTime <- read.csv(\"ResponseTime.csv\")\nQ1.13mean <- mean(ResponseTime$Q1.2013)\nQ1.13std <- sd(ResponseTime$Q1.2013)\nQ1.13mean\nQ1.13std\n\n# Compute the z-test for first and second quarter. I guess \"first and second quarter\"\n# means first and second quarter in 2013\nattach(ResponseTime)\n\n# one sample z test\nz1 = z.test(Q1.2013, sigma.x = Q1.13std, mu = Q1.13mean)\nz1\nz2 = z.test(Q2.2013, sigma.x = sd(Q2.2013), mu = mean(Q2.2013))\nz2\n# 2 sample z test\nz.test(Q1.2013, Q2.2013, sigma.x = sd(Q1.2013), sigma.y = sd(Q2.2013))\n```\nBased on the result, we accept the null hypothesis, which means the response time for first and seconde quarter of year 2013 are both normal distrubuted with the same mean.\nSo we can use 95% confidence interval of first quarter of year 2013, [`r z1$conf.int[1]`, `r z1$conf.int[2]`].\nas the estimates to give customers for response times to customer service calls.\n\n### 3. Have the data in the data file DefectsAfterDelivery.csv changed significantly over the past 5 years?\n```{r Q3, echo = T, comment = NA}\n# excel_sheets(\"Performance_Lawn_Equipment_Database.xlsx\")\nPLE_path <- file.path(\"Performance_Lawn_Equipment_Database.xlsx\")\nTransmissionCosts <- read_excel(PLE_path, sheet = \"Transmission Costs\", skip = 2)\ncurrent.sd <- sd(TransmissionCosts$Current)\n\n# normality test of Current\nattach(TransmissionCosts)\nshapiro.test(Current)\n# ad.test(Current)\n```\nNotice that $p>0.05$, so we accept the null hypothesis that the current process costs for building transmissions is under normal distribution. We can apply the same normality test on Process A and Process B\n```{r, echo = T, comment = NA}\nshapiro.test(`Process A`)\nshapiro.test(`Process B`)\n```\nFrom the result, we accept the null hypothesis that both of them are under normal distribution. Then we can conduct a two sample z test to compare the mean of current process and alternative processes.\n```{r, echo=T, comment=NA}\n# z.test(TransmissionCosts$Current, sigma.x = current.sd, mu = mean(TransmissionCosts$Current))\n\n# apply z.test for other 2 processes\nz.test(`Process A`, Current, sigma.x = mean(`Process A`), sigma.y = mean(Current))\nz.test(`Process B`, Current, sigma.x = mean(`Process B`), sigma.y = mean(Current))\n```\nBased on the results, we accept the null hypothesis, which means the Process A and Process B are not better than current process.\n\n### 4. Although engineering has collected data on alternative process costs for building transmissions in the data file TransmissionCosts.csv, why didn’t they reach a conclusion as to whether one of the proposed processes is better than the current process?\n```{r Q4, echo = T, comment = NA}\nMowerTest <- read_excel(PLE_path, sheet = \"Mower Test\", skip = 3)\nMowerTest <- MowerTest %>% mutate_all(as.factor)\nattach(MowerTest)\n# Convert the Pass/Fail levels to numeric values\n\nB <- MowerTest %>% group_by(Observation) %>% \n  mutate_all(function(x) ifelse(x == \"Pass\", 1, 0)) %>% \n  mutate_all(as.numeric)\n\n# Total number of failures:\nlength(which(B == 0))\n\n# calculate mean of B\nmeanB <- B %>% ungroup %>% select(-Observation) %>% apply(1, mean) %>% mean\n\n# use t test on B\nB <- B %>% ungroup %>% select(-Observation) %>% apply(1, mean)\nt <- t.test(B, mu = meanB)\nt\n```\nBased on the result, we accept the null hypothesis. So a 95% confidence interval for\nan additional sample of mower test performance as in the worksheet Mower Test\nis [`r t$conf.int[1]`, `r t$conf.int[2]`]\n\n### 5. Are there differences in employee retention due to gender, college graduation status, or whether the employee is from the local area in the data in the ata file EmployeeRetention.csv?\n```{r Q5, echo=T, comment = NA}\nBladeWeight <- read_excel(PLE_path, \"Blade Weight\", skip = 2)\nhist(BladeWeight$Weight)\nmean(BladeWeight$Weight)\nsd(BladeWeight$Weight)\n# Compute the standard error of the mean \nattach(BladeWeight)\nsem <- sd(Weight)/sqrt(length(Weight))\nsem\n\n# test normality\nA <- lm(BladeWeight$Weight ~ ., BladeWeight)\npar(mfrow = c(2,2))\nplot(A)\n```\nWe could see that there is a significant outlier 171. That will affect the test for normality. Remove this outlier and apply a normality test\n```{r, echo = T, comment = NA}\nqqnorm(Weight[-171])\nqqline(Weight[-171])\n\n# run a normality test:\nshapiro.test(Weight[-171])\n```\nbased on result we should accept the null hypothesis.\n",
    "created" : 1503154645024.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2478270491",
    "id" : "316FA95E",
    "lastKnownWriteTime" : 1503154922,
    "last_content_update" : 1503154922746,
    "path" : "~/Documents/Harrisburg/500_52/Lab#1 P5.Rmd",
    "project_path" : null,
    "properties" : {
        "last_setup_crc32" : "",
        "marks" : "<:136,0\n>:136,0",
        "tempName" : "Untitled3"
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}